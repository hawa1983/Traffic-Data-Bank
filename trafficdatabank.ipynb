{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVu61kgwS5TUGoq1O3yKW2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hawa1983/Traffic-Data-Bank/blob/main/trafficdatabank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L7K5pkY19dS",
        "outputId": "9a37d118-5ed4-4db7-c9ed-881e9109a421"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved per-observation classifications to: Port_Jefferson_LP_Classified_Observations.csv\n",
            "Saved final per-plate classifications to: Port_Jefferson_LP_Final_By_Plate.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# --------- Config ----------\n",
        "CSV_PATH = \"Port_Jefferson_LP_Count_Cleaned.csv\"\n",
        "\n",
        "PLATE_COL = \"Plate\"\n",
        "LOCATION_COL = \"Location\"\n",
        "DIRECTION_COL = \"Direction\"\n",
        "TIME_COL = \"Time\"              # <- in file\n",
        "TIMESTAMP_COL = \"Timestamp\"    # <- will be created\n",
        "\n",
        "# Use any single date; you said same date is fine\n",
        "BASE_DATE = \"2025-01-01\"\n",
        "\n",
        "WINDOW_MIN = 15\n",
        "# ---------------------------\n",
        "\n",
        "def normalize_text(s):\n",
        "    if pd.isna(s):\n",
        "        return s\n",
        "    return str(s).strip().lower()\n",
        "\n",
        "def appears_within(df_plate, idx, pairs, window_min=15):\n",
        "    t0 = df_plate.loc[idx, TIMESTAMP_COL]\n",
        "    mask = (df_plate[TIMESTAMP_COL] > t0) & (df_plate[TIMESTAMP_COL] <= t0 + pd.Timedelta(minutes=window_min))\n",
        "    if not mask.any():\n",
        "        return False\n",
        "    future = df_plate.loc[mask, [LOCATION_COL, DIRECTION_COL]]\n",
        "    for loc, direc in pairs:\n",
        "        if ((future[LOCATION_COL] == loc) & (future[DIRECTION_COL] == direc)).any():\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def no_other_appearance_within(df_plate, idx, window_min=15):\n",
        "    t0 = df_plate.loc[idx, TIMESTAMP_COL]\n",
        "    loc0 = df_plate.loc[idx, LOCATION_COL]\n",
        "    mask = (df_plate[TIMESTAMP_COL] > t0) & (df_plate[TIMESTAMP_COL] <= t0 + pd.Timedelta(minutes=window_min))\n",
        "    if not mask.any():\n",
        "        return True\n",
        "    future = df_plate.loc[mask, [LOCATION_COL]]\n",
        "    return (future[LOCATION_COL] == loc0).all()\n",
        "\n",
        "def classify_observation(row, df_plate, idx):\n",
        "    loc = row[LOCATION_COL]\n",
        "    direc = row[DIRECTION_COL]\n",
        "\n",
        "    # Rule 1\n",
        "    if ((loc == \"woodhull ave\" and direc == \"northbound\") or\n",
        "        (loc == \"lincoln ave\" and direc == \"northbound\")):\n",
        "        pairs = [(\"ardmer dr\", \"eastbound\"), (\"chereb lane\", \"eastbound\")]\n",
        "        return \"Pass Thru\" if appears_within(df_plate, idx, pairs, WINDOW_MIN) else \"Resident Entry\"\n",
        "\n",
        "    # Rule 2\n",
        "    if ((loc == \"ardmer dr\" and direc == \"westbound\") or\n",
        "        (loc == \"chereb lane\" and direc == \"westbound\")):\n",
        "        pairs = [(\"woodhull ave\", \"southbound\"),\n",
        "                 (\"lincoln ave\", \"southbound\"),\n",
        "                 (\"norwood ave\", \"westbound\")]\n",
        "        return \"Pass Thru\" if appears_within(df_plate, idx, pairs, WINDOW_MIN) else \"Resident Entry\"\n",
        "\n",
        "    # Rule 3\n",
        "    if (loc == \"norwood ave\" and direc == \"eastbound\"):\n",
        "        pairs = [(\"ardmer dr\", \"eastbound\"), (\"chereb lane\", \"eastbound\")]\n",
        "        return \"Pass Thru\" if appears_within(df_plate, idx, pairs, WINDOW_MIN) else \"HWY Bound or Resident Entry\"\n",
        "\n",
        "    # Rule 4 (exits)\n",
        "    if ((loc == \"woodhull ave\" and direc == \"southbound\") or\n",
        "        (loc == \"lincoln ave\" and direc == \"southbound\") or\n",
        "        (loc == \"ardmer dr\" and direc == \"eastbound\") or\n",
        "        (loc == \"chereb lane\" and direc == \"eastbound\")):\n",
        "        if no_other_appearance_within(df_plate, idx, WINDOW_MIN):\n",
        "            return \"Resident Exit\"\n",
        "\n",
        "    return \"Unclassified\"\n",
        "\n",
        "def final_plate_classification(per_obs_classes):\n",
        "    priority = [\"Pass Thru\", \"Resident Exit\", \"Resident Entry\", \"HWY Bound or Resident Entry\", \"Unclassified\"]\n",
        "    for label in priority:\n",
        "        if label in per_obs_classes:\n",
        "            return label\n",
        "    return \"Unclassified\"\n",
        "\n",
        "def main():\n",
        "    df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "    # Build Timestamp from single date + Time column (e.g., \"6:00 AM\")\n",
        "    # Example result: \"2025-01-01 06:00 AM\"\n",
        "    df[TIMESTAMP_COL] = pd.to_datetime(BASE_DATE + \" \" + df[TIME_COL].astype(str), errors=\"coerce\")\n",
        "\n",
        "    # Normalize for matching\n",
        "    df[\"_loc_norm\"] = df[LOCATION_COL].map(normalize_text)\n",
        "    df[\"_dir_norm\"] = df[DIRECTION_COL].map(normalize_text)\n",
        "\n",
        "    # Use normalized for rule logic (keep originals in separate cols if you like)\n",
        "    df[LOCATION_COL] = df[\"_loc_norm\"]\n",
        "    df[DIRECTION_COL] = df[\"_dir_norm\"]\n",
        "\n",
        "    # Sort by plate then time\n",
        "    df = df.sort_values([PLATE_COL, TIMESTAMP_COL]).reset_index(drop=True)\n",
        "\n",
        "    # Classify each observation\n",
        "    classifications = []\n",
        "    for plate, _ in df.groupby(PLATE_COL, sort=False):\n",
        "        df_plate = df[df[PLATE_COL] == plate]  # already sorted\n",
        "        for idx in df_plate.index:\n",
        "            cls = classify_observation(df.loc[idx], df_plate, idx)\n",
        "            classifications.append((idx, cls))\n",
        "\n",
        "    df[\"Observation_Classification\"] = pd.Series(dict(classifications))\n",
        "\n",
        "    # Final per-plate\n",
        "    plate_final = (\n",
        "        df.groupby(PLATE_COL)[\"Observation_Classification\"]\n",
        "          .apply(lambda s: final_plate_classification(set(s.dropna())))\n",
        "          .rename(\"Plate_Final_Classification\")\n",
        "          .reset_index()\n",
        "    )\n",
        "\n",
        "    # Output\n",
        "    out_obs = Path(CSV_PATH).with_name(\"Port_Jefferson_LP_Classified_Observations.csv\")\n",
        "    out_plate = Path(CSV_PATH).with_name(\"Port_Jefferson_LP_Final_By_Plate.csv\")\n",
        "\n",
        "    df_out = df.drop(columns=[\"_loc_norm\", \"_dir_norm\"])\n",
        "    df_out.to_csv(out_obs, index=False)\n",
        "    plate_final.to_csv(out_plate, index=False)\n",
        "\n",
        "    print(f\"Saved per-observation classifications to: {out_obs}\")\n",
        "    print(f\"Saved final per-plate classifications to: {out_plate}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New"
      ],
      "metadata": {
        "id": "iYL1iFS63LkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# --------- Config ----------\n",
        "CSV_PATH = \"Port_Jefferson_LP_Count_Cleaned.csv\"\n",
        "\n",
        "PLATE_COL = \"Plate\"\n",
        "LOCATION_COL = \"Location\"\n",
        "DIRECTION_COL = \"Direction\"\n",
        "PERIOD_COL = \"Period\"\n",
        "TIME_COL = \"Time\"              # <- in file (e.g., \"6:00 AM\")\n",
        "TIMESTAMP_COL = \"Timestamp\"    # <- we will create\n",
        "\n",
        "# Use any single date; same date for all times is fine\n",
        "BASE_DATE = \"2025-01-01\"\n",
        "\n",
        "WINDOW_MIN = 15\n",
        "# ---------------------------\n",
        "\n",
        "def normalize_text(s):\n",
        "    if pd.isna(s):\n",
        "        return s\n",
        "    return str(s).strip().lower()\n",
        "\n",
        "def find_match_within(df_plate, idx, pairs, window_min=15):\n",
        "    \"\"\"\n",
        "    Return (matched:bool, match_row:Series|None) for any of the (location, direction) pairs\n",
        "    within the forward time window from this observation.\n",
        "    \"\"\"\n",
        "    t0 = df_plate.loc[idx, TIMESTAMP_COL]\n",
        "    mask = (df_plate[TIMESTAMP_COL] > t0) & (df_plate[TIMESTAMP_COL] <= t0 + pd.Timedelta(minutes=window_min))\n",
        "    if not mask.any():\n",
        "        return False, None\n",
        "    future = df_plate.loc[mask]\n",
        "    for loc, direc in pairs:\n",
        "        hit = future[(future[LOCATION_COL] == loc) & (future[DIRECTION_COL] == direc)]\n",
        "        if not hit.empty:\n",
        "            # take earliest match\n",
        "            j = hit.index[0]\n",
        "            return True, df_plate.loc[j]\n",
        "    return False, None\n",
        "\n",
        "def no_other_appearance_within(df_plate, idx, window_min=15):\n",
        "    t0 = df_plate.loc[idx, TIMESTAMP_COL]\n",
        "    loc0 = df_plate.loc[idx, LOCATION_COL]\n",
        "    mask = (df_plate[TIMESTAMP_COL] > t0) & (df_plate[TIMESTAMP_COL] <= t0 + pd.Timedelta(minutes=window_min))\n",
        "    if not mask.any():\n",
        "        return True\n",
        "    future = df_plate.loc[mask, [LOCATION_COL]]\n",
        "    return (future[LOCATION_COL] == loc0).all()\n",
        "\n",
        "def classify_observation(row, df_plate, idx):\n",
        "    loc = row[LOCATION_COL]\n",
        "    direc = row[DIRECTION_COL]\n",
        "\n",
        "    # Defaults for match details\n",
        "    match = {\n",
        "        \"Match_Location\": None,\n",
        "        \"Match_Direction\": None,\n",
        "        \"Match_Timestamp\": pd.NaT\n",
        "    }\n",
        "\n",
        "    # Rule 1: Entry S->N\n",
        "    if ((loc == \"woodhull ave\" and direc == \"northbound\") or\n",
        "        (loc == \"lincoln ave\" and direc == \"northbound\")):\n",
        "        pairs = [(\"ardmer dr\", \"eastbound\"), (\"chereb lane\", \"eastbound\")]\n",
        "        ok, mrow = find_match_within(df_plate, idx, pairs, WINDOW_MIN)\n",
        "        if ok:\n",
        "            match.update({\n",
        "                \"Match_Location\": mrow[LOCATION_COL],\n",
        "                \"Match_Direction\": mrow[DIRECTION_COL],\n",
        "                \"Match_Timestamp\": mrow[TIMESTAMP_COL]\n",
        "            })\n",
        "            return \"Pass Thru\", match\n",
        "        else:\n",
        "            return \"Resident Entry\", match\n",
        "\n",
        "    # Rule 2: Entry E->W\n",
        "    if ((loc == \"ardmer dr\" and direc == \"westbound\") or\n",
        "        (loc == \"chereb lane\" and direc == \"westbound\")):\n",
        "        pairs = [(\"woodhull ave\", \"southbound\"),\n",
        "                 (\"lincoln ave\", \"southbound\"),\n",
        "                 (\"norwood ave\", \"westbound\")]\n",
        "        ok, mrow = find_match_within(df_plate, idx, pairs, WINDOW_MIN)\n",
        "        if ok:\n",
        "            match.update({\n",
        "                \"Match_Location\": mrow[LOCATION_COL],\n",
        "                \"Match_Direction\": mrow[DIRECTION_COL],\n",
        "                \"Match_Timestamp\": mrow[TIMESTAMP_COL]\n",
        "            })\n",
        "            return \"Pass Thru\", match\n",
        "        else:\n",
        "            return \"Resident Entry\", match\n",
        "\n",
        "    # Rule 3: Entry from West via Norwood EB\n",
        "    if (loc == \"norwood ave\" and direc == \"eastbound\"):\n",
        "        pairs = [(\"ardmer dr\", \"eastbound\"), (\"chereb lane\", \"eastbound\")]\n",
        "        ok, mrow = find_match_within(df_plate, idx, pairs, WINDOW_MIN)\n",
        "        if ok:\n",
        "            match.update({\n",
        "                \"Match_Location\": mrow[LOCATION_COL],\n",
        "                \"Match_Direction\": mrow[DIRECTION_COL],\n",
        "                \"Match_Timestamp\": mrow[TIMESTAMP_COL]\n",
        "            })\n",
        "            return \"Pass Thru\", match\n",
        "        else:\n",
        "            return \"HWY Bound or Resident Entry\", match\n",
        "\n",
        "    # Rule 4: Exit\n",
        "    if ((loc == \"woodhull ave\" and direc == \"southbound\") or\n",
        "        (loc == \"lincoln ave\" and direc == \"southbound\") or\n",
        "        (loc == \"ardmer dr\" and direc == \"eastbound\") or\n",
        "        (loc == \"chereb lane\" and direc == \"eastbound\")):\n",
        "        if no_other_appearance_within(df_plate, idx, WINDOW_MIN):\n",
        "            return \"Resident Exit\", match\n",
        "\n",
        "    return \"Unclassified\", match\n",
        "\n",
        "def final_plate_classification(per_obs_classes):\n",
        "    # Priority for final roll-up\n",
        "    priority = [\"Pass Thru\", \"Resident Exit\", \"Resident Entry\", \"HWY Bound or Resident Entry\", \"Unclassified\"]\n",
        "    for label in priority:\n",
        "        if label in per_obs_classes:\n",
        "            return label\n",
        "    return \"Unclassified\"\n",
        "\n",
        "def main():\n",
        "    df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "    # Build a Timestamp from BASE_DATE + Time (e.g., \"6:00 AM\")\n",
        "    df[TIMESTAMP_COL] = pd.to_datetime(BASE_DATE + \" \" + df[TIME_COL].astype(str), errors=\"coerce\")\n",
        "\n",
        "    # Normalize for rule matching (keep originals too)\n",
        "    df[\"_loc_norm\"] = df[LOCATION_COL].map(normalize_text)\n",
        "    df[\"_dir_norm\"] = df[DIRECTION_COL].map(normalize_text)\n",
        "\n",
        "    # Use normalized fields for rules\n",
        "    df[LOCATION_COL] = df[\"_loc_norm\"]\n",
        "    df[DIRECTION_COL] = df[\"_dir_norm\"]\n",
        "\n",
        "    # Sort\n",
        "    df = df.sort_values([PLATE_COL, TIMESTAMP_COL]).reset_index(drop=True)\n",
        "\n",
        "    # Per-observation classification + match details\n",
        "    obs_cls = []\n",
        "    match_loc = []\n",
        "    match_dir = []\n",
        "    match_ts = []\n",
        "\n",
        "    for plate, plate_grp in df.groupby(PLATE_COL, sort=False):\n",
        "        df_plate = plate_grp  # already sorted slice\n",
        "        for idx in df_plate.index:\n",
        "            cls, match = classify_observation(df.loc[idx], df[df[PLATE_COL] == plate], idx)\n",
        "            obs_cls.append((idx, cls))\n",
        "            match_loc.append((idx, match[\"Match_Location\"]))\n",
        "            match_dir.append((idx, match[\"Match_Direction\"]))\n",
        "            match_ts.append((idx, match[\"Match_Timestamp\"]))\n",
        "\n",
        "    df[\"Observation_Classification\"] = pd.Series(dict(obs_cls))\n",
        "    df[\"Match_Location\"] = pd.Series(dict(match_loc))\n",
        "    df[\"Match_Direction\"] = pd.Series(dict(match_dir))\n",
        "    df[\"Match_Timestamp\"] = pd.Series(dict(match_ts))\n",
        "\n",
        "    # Plate-level final classification\n",
        "    plate_final = (\n",
        "        df.groupby(PLATE_COL)[\"Observation_Classification\"]\n",
        "          .apply(lambda s: final_plate_classification(set(s.dropna())))\n",
        "          .rename(\"Plate_Final_Classification\")\n",
        "          .reset_index()\n",
        "    )\n",
        "\n",
        "    # Merge plate final back to each row\n",
        "    df = df.merge(plate_final, on=PLATE_COL, how=\"left\")\n",
        "\n",
        "    # ---------- Output 1: full_tracking_classified.csv ----------\n",
        "    full_tracking_cols = [\n",
        "        PLATE_COL, LOCATION_COL, DIRECTION_COL, PERIOD_COL, TIME_COL, TIMESTAMP_COL,\n",
        "        \"Observation_Classification\", \"Plate_Final_Classification\",\n",
        "        \"Match_Location\", \"Match_Direction\", \"Match_Timestamp\"\n",
        "    ]\n",
        "    # Restore original-cased Location/Direction if desired\n",
        "    # (You can comment these two lines if you prefer normalized in the export)\n",
        "    if \"_loc_norm\" in df.columns and \"_dir_norm\" in df.columns:\n",
        "        df[\"Location_Original\"] = df[\"_loc_norm\"]\n",
        "        df[\"Direction_Original\"] = df[\"_dir_norm\"]\n",
        "\n",
        "    out_full = \"full_tracking_classified.csv\"\n",
        "    df[full_tracking_cols].to_csv(out_full, index=False)\n",
        "\n",
        "    # ---------- Output 2: pass_thru_summary.csv ----------\n",
        "    pass_thru = df[df[\"Observation_Classification\"] == \"Pass Thru\"].copy()\n",
        "    if not pass_thru.empty:\n",
        "        pass_thru[\"Entry_Timestamp\"] = pass_thru[TIMESTAMP_COL]\n",
        "        pass_thru[\"Exit_Timestamp\"] = pass_thru[\"Match_Timestamp\"]\n",
        "        pass_thru[\"Minutes_Between\"] = (pass_thru[\"Exit_Timestamp\"] - pass_thru[\"Entry_Timestamp\"]).dt.total_seconds() / 60.0\n",
        "        pass_thru[\"Entry_Point\"] = pass_thru[LOCATION_COL].str.title() + \" \" + pass_thru[DIRECTION_COL].str.title()\n",
        "        pass_thru[\"Exit_Point\"] = pass_thru[\"Match_Location\"].fillna(\"\").str.title() + \" \" + pass_thru[\"Match_Direction\"].fillna(\"\").str.title()\n",
        "        pass_thru[\"Path\"] = pass_thru[\"Entry_Point\"] + \" -> \" + pass_thru[\"Exit_Point\"]\n",
        "\n",
        "        pass_thru_cols = [\n",
        "            PLATE_COL, \"Entry_Timestamp\", \"Exit_Timestamp\", \"Minutes_Between\",\n",
        "            \"Entry_Point\", \"Exit_Point\", \"Path\"\n",
        "        ]\n",
        "        pass_thru = pass_thru.sort_values([PLATE_COL, \"Entry_Timestamp\"])\n",
        "        pass_thru[pass_thru_cols].to_csv(\"pass_thru_summary.csv\", index=False)\n",
        "    else:\n",
        "        # write empty schema if none\n",
        "        pd.DataFrame(columns=[\n",
        "            PLATE_COL, \"Entry_Timestamp\", \"Exit_Timestamp\", \"Minutes_Between\",\n",
        "            \"Entry_Point\", \"Exit_Point\", \"Path\"\n",
        "        ]).to_csv(\"pass_thru_summary.csv\", index=False)\n",
        "\n",
        "    # ---------- Output 3: all_movements_summary.csv ----------\n",
        "    # Aggregate by Location/Direction/Period/Time\n",
        "    grp = df.groupby([LOCATION_COL, DIRECTION_COL, PERIOD_COL, TIME_COL], dropna=False)\n",
        "    summary = grp.agg(\n",
        "        Observations=(\"Plate\", \"count\"),\n",
        "        UniquePlates=(\"Plate\", pd.Series.nunique)\n",
        "    ).reset_index()\n",
        "\n",
        "    summary = summary.sort_values([LOCATION_COL, DIRECTION_COL, PERIOD_COL, TIME_COL])\n",
        "    summary.to_csv(\"all_movements_summary.csv\", index=False)\n",
        "\n",
        "    print(f\"Saved:\\n- {out_full}\\n- pass_thru_summary.csv\\n- all_movements_summary.csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anYFlc5D3EAi",
        "outputId": "82c50eb8-f566-4a1a-e119-1ed6428e6a81"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved:\n",
            "- full_tracking_classified.csv\n",
            "- pass_thru_summary.csv\n",
            "- all_movements_summary.csv\n"
          ]
        }
      ]
    }
  ]
}