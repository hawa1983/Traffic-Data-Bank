{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNba0/IrXFkKi2Tr8SgjTsv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hawa1983/Traffic-Data-Bank/blob/main/trafficdatabank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L7K5pkY19dS",
        "outputId": "9a37d118-5ed4-4db7-c9ed-881e9109a421"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved per-observation classifications to: Port_Jefferson_LP_Classified_Observations.csv\n",
            "Saved final per-plate classifications to: Port_Jefferson_LP_Final_By_Plate.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# --------- Config ----------\n",
        "CSV_PATH = \"Port_Jefferson_LP_Count_Cleaned.csv\"\n",
        "\n",
        "PLATE_COL = \"Plate\"\n",
        "LOCATION_COL = \"Location\"\n",
        "DIRECTION_COL = \"Direction\"\n",
        "TIME_COL = \"Time\"              # <- in file\n",
        "TIMESTAMP_COL = \"Timestamp\"    # <- will be created\n",
        "\n",
        "# Use any single date; you said same date is fine\n",
        "BASE_DATE = \"2025-01-01\"\n",
        "\n",
        "WINDOW_MIN = 15\n",
        "# ---------------------------\n",
        "\n",
        "def normalize_text(s):\n",
        "    if pd.isna(s):\n",
        "        return s\n",
        "    return str(s).strip().lower()\n",
        "\n",
        "def appears_within(df_plate, idx, pairs, window_min=15):\n",
        "    t0 = df_plate.loc[idx, TIMESTAMP_COL]\n",
        "    mask = (df_plate[TIMESTAMP_COL] > t0) & (df_plate[TIMESTAMP_COL] <= t0 + pd.Timedelta(minutes=window_min))\n",
        "    if not mask.any():\n",
        "        return False\n",
        "    future = df_plate.loc[mask, [LOCATION_COL, DIRECTION_COL]]\n",
        "    for loc, direc in pairs:\n",
        "        if ((future[LOCATION_COL] == loc) & (future[DIRECTION_COL] == direc)).any():\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def no_other_appearance_within(df_plate, idx, window_min=15):\n",
        "    t0 = df_plate.loc[idx, TIMESTAMP_COL]\n",
        "    loc0 = df_plate.loc[idx, LOCATION_COL]\n",
        "    mask = (df_plate[TIMESTAMP_COL] > t0) & (df_plate[TIMESTAMP_COL] <= t0 + pd.Timedelta(minutes=window_min))\n",
        "    if not mask.any():\n",
        "        return True\n",
        "    future = df_plate.loc[mask, [LOCATION_COL]]\n",
        "    return (future[LOCATION_COL] == loc0).all()\n",
        "\n",
        "def classify_observation(row, df_plate, idx):\n",
        "    loc = row[LOCATION_COL]\n",
        "    direc = row[DIRECTION_COL]\n",
        "\n",
        "    # Rule 1\n",
        "    if ((loc == \"woodhull ave\" and direc == \"northbound\") or\n",
        "        (loc == \"lincoln ave\" and direc == \"northbound\")):\n",
        "        pairs = [(\"ardmer dr\", \"eastbound\"), (\"chereb lane\", \"eastbound\")]\n",
        "        return \"Pass Thru\" if appears_within(df_plate, idx, pairs, WINDOW_MIN) else \"Resident Entry\"\n",
        "\n",
        "    # Rule 2\n",
        "    if ((loc == \"ardmer dr\" and direc == \"westbound\") or\n",
        "        (loc == \"chereb lane\" and direc == \"westbound\")):\n",
        "        pairs = [(\"woodhull ave\", \"southbound\"),\n",
        "                 (\"lincoln ave\", \"southbound\"),\n",
        "                 (\"norwood ave\", \"westbound\")]\n",
        "        return \"Pass Thru\" if appears_within(df_plate, idx, pairs, WINDOW_MIN) else \"Resident Entry\"\n",
        "\n",
        "    # Rule 3\n",
        "    if (loc == \"norwood ave\" and direc == \"eastbound\"):\n",
        "        pairs = [(\"ardmer dr\", \"eastbound\"), (\"chereb lane\", \"eastbound\")]\n",
        "        return \"Pass Thru\" if appears_within(df_plate, idx, pairs, WINDOW_MIN) else \"HWY Bound or Resident Entry\"\n",
        "\n",
        "    # Rule 4 (exits)\n",
        "    if ((loc == \"woodhull ave\" and direc == \"southbound\") or\n",
        "        (loc == \"lincoln ave\" and direc == \"southbound\") or\n",
        "        (loc == \"ardmer dr\" and direc == \"eastbound\") or\n",
        "        (loc == \"chereb lane\" and direc == \"eastbound\")):\n",
        "        if no_other_appearance_within(df_plate, idx, WINDOW_MIN):\n",
        "            return \"Resident Exit\"\n",
        "\n",
        "    return \"Unclassified\"\n",
        "\n",
        "def final_plate_classification(per_obs_classes):\n",
        "    priority = [\"Pass Thru\", \"Resident Exit\", \"Resident Entry\", \"HWY Bound or Resident Entry\", \"Unclassified\"]\n",
        "    for label in priority:\n",
        "        if label in per_obs_classes:\n",
        "            return label\n",
        "    return \"Unclassified\"\n",
        "\n",
        "def main():\n",
        "    df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "    # Build Timestamp from single date + Time column (e.g., \"6:00 AM\")\n",
        "    # Example result: \"2025-01-01 06:00 AM\"\n",
        "    df[TIMESTAMP_COL] = pd.to_datetime(BASE_DATE + \" \" + df[TIME_COL].astype(str), errors=\"coerce\")\n",
        "\n",
        "    # Normalize for matching\n",
        "    df[\"_loc_norm\"] = df[LOCATION_COL].map(normalize_text)\n",
        "    df[\"_dir_norm\"] = df[DIRECTION_COL].map(normalize_text)\n",
        "\n",
        "    # Use normalized for rule logic (keep originals in separate cols if you like)\n",
        "    df[LOCATION_COL] = df[\"_loc_norm\"]\n",
        "    df[DIRECTION_COL] = df[\"_dir_norm\"]\n",
        "\n",
        "    # Sort by plate then time\n",
        "    df = df.sort_values([PLATE_COL, TIMESTAMP_COL]).reset_index(drop=True)\n",
        "\n",
        "    # Classify each observation\n",
        "    classifications = []\n",
        "    for plate, _ in df.groupby(PLATE_COL, sort=False):\n",
        "        df_plate = df[df[PLATE_COL] == plate]  # already sorted\n",
        "        for idx in df_plate.index:\n",
        "            cls = classify_observation(df.loc[idx], df_plate, idx)\n",
        "            classifications.append((idx, cls))\n",
        "\n",
        "    df[\"Observation_Classification\"] = pd.Series(dict(classifications))\n",
        "\n",
        "    # Final per-plate\n",
        "    plate_final = (\n",
        "        df.groupby(PLATE_COL)[\"Observation_Classification\"]\n",
        "          .apply(lambda s: final_plate_classification(set(s.dropna())))\n",
        "          .rename(\"Plate_Final_Classification\")\n",
        "          .reset_index()\n",
        "    )\n",
        "\n",
        "    # Output\n",
        "    out_obs = Path(CSV_PATH).with_name(\"Port_Jefferson_LP_Classified_Observations.csv\")\n",
        "    out_plate = Path(CSV_PATH).with_name(\"Port_Jefferson_LP_Final_By_Plate.csv\")\n",
        "\n",
        "    df_out = df.drop(columns=[\"_loc_norm\", \"_dir_norm\"])\n",
        "    df_out.to_csv(out_obs, index=False)\n",
        "    plate_final.to_csv(out_plate, index=False)\n",
        "\n",
        "    print(f\"Saved per-observation classifications to: {out_obs}\")\n",
        "    print(f\"Saved final per-plate classifications to: {out_plate}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New"
      ],
      "metadata": {
        "id": "iYL1iFS63LkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# --------- Config ----------\n",
        "CSV_PATH = \"Port_Jefferson_LP_Count_Cleaned.csv\"\n",
        "\n",
        "PLATE_COL = \"Plate\"\n",
        "LOCATION_COL = \"Location\"\n",
        "DIRECTION_COL = \"Direction\"\n",
        "PERIOD_COL = \"Period\"\n",
        "TIME_COL = \"Time\"              # <- in file (e.g., \"6:00 AM\")\n",
        "TIMESTAMP_COL = \"Timestamp\"    # <- we will create\n",
        "\n",
        "# Use any single date; same date for all times is fine\n",
        "BASE_DATE = \"2025-01-01\"\n",
        "\n",
        "WINDOW_MIN = 15\n",
        "# ---------------------------\n",
        "\n",
        "def normalize_text(s):\n",
        "    if pd.isna(s):\n",
        "        return s\n",
        "    return str(s).strip().lower()\n",
        "\n",
        "def find_match_within(df_plate, idx, pairs, window_min=15):\n",
        "    \"\"\"\n",
        "    Return (matched:bool, match_row:Series|None) for any of the (location, direction) pairs\n",
        "    within the forward time window from this observation.\n",
        "    \"\"\"\n",
        "    t0 = df_plate.loc[idx, TIMESTAMP_COL]\n",
        "    mask = (df_plate[TIMESTAMP_COL] > t0) & (df_plate[TIMESTAMP_COL] <= t0 + pd.Timedelta(minutes=window_min))\n",
        "    if not mask.any():\n",
        "        return False, None\n",
        "    future = df_plate.loc[mask]\n",
        "    for loc, direc in pairs:\n",
        "        hit = future[(future[LOCATION_COL] == loc) & (future[DIRECTION_COL] == direc)]\n",
        "        if not hit.empty:\n",
        "            # take earliest match\n",
        "            j = hit.index[0]\n",
        "            return True, df_plate.loc[j]\n",
        "    return False, None\n",
        "\n",
        "def no_other_appearance_within(df_plate, idx, window_min=15):\n",
        "    t0 = df_plate.loc[idx, TIMESTAMP_COL]\n",
        "    loc0 = df_plate.loc[idx, LOCATION_COL]\n",
        "    mask = (df_plate[TIMESTAMP_COL] > t0) & (df_plate[TIMESTAMP_COL] <= t0 + pd.Timedelta(minutes=window_min))\n",
        "    if not mask.any():\n",
        "        return True\n",
        "    future = df_plate.loc[mask, [LOCATION_COL]]\n",
        "    return (future[LOCATION_COL] == loc0).all()\n",
        "\n",
        "def classify_observation(row, df_plate, idx):\n",
        "    loc = row[LOCATION_COL]\n",
        "    direc = row[DIRECTION_COL]\n",
        "\n",
        "    # Defaults for match details\n",
        "    match = {\n",
        "        \"Match_Location\": None,\n",
        "        \"Match_Direction\": None,\n",
        "        \"Match_Timestamp\": pd.NaT\n",
        "    }\n",
        "\n",
        "    # Rule 1: Entry S->N\n",
        "    if ((loc == \"woodhull ave\" and direc == \"northbound\") or\n",
        "        (loc == \"lincoln ave\" and direc == \"northbound\")):\n",
        "        pairs = [(\"ardmer dr\", \"eastbound\"), (\"chereb lane\", \"eastbound\")]\n",
        "        ok, mrow = find_match_within(df_plate, idx, pairs, WINDOW_MIN)\n",
        "        if ok:\n",
        "            match.update({\n",
        "                \"Match_Location\": mrow[LOCATION_COL],\n",
        "                \"Match_Direction\": mrow[DIRECTION_COL],\n",
        "                \"Match_Timestamp\": mrow[TIMESTAMP_COL]\n",
        "            })\n",
        "            return \"Pass Thru\", match\n",
        "        else:\n",
        "            return \"Resident Entry\", match\n",
        "\n",
        "    # Rule 2: Entry E->W\n",
        "    if ((loc == \"ardmer dr\" and direc == \"westbound\") or\n",
        "        (loc == \"chereb lane\" and direc == \"westbound\")):\n",
        "        pairs = [(\"woodhull ave\", \"southbound\"),\n",
        "                 (\"lincoln ave\", \"southbound\"),\n",
        "                 (\"norwood ave\", \"westbound\")]\n",
        "        ok, mrow = find_match_within(df_plate, idx, pairs, WINDOW_MIN)\n",
        "        if ok:\n",
        "            match.update({\n",
        "                \"Match_Location\": mrow[LOCATION_COL],\n",
        "                \"Match_Direction\": mrow[DIRECTION_COL],\n",
        "                \"Match_Timestamp\": mrow[TIMESTAMP_COL]\n",
        "            })\n",
        "            return \"Pass Thru\", match\n",
        "        else:\n",
        "            return \"Resident Entry\", match\n",
        "\n",
        "    # Rule 3: Entry from West via Norwood EB\n",
        "    if (loc == \"norwood ave\" and direc == \"eastbound\"):\n",
        "        pairs = [(\"ardmer dr\", \"eastbound\"), (\"chereb lane\", \"eastbound\")]\n",
        "        ok, mrow = find_match_within(df_plate, idx, pairs, WINDOW_MIN)\n",
        "        if ok:\n",
        "            match.update({\n",
        "                \"Match_Location\": mrow[LOCATION_COL],\n",
        "                \"Match_Direction\": mrow[DIRECTION_COL],\n",
        "                \"Match_Timestamp\": mrow[TIMESTAMP_COL]\n",
        "            })\n",
        "            return \"Pass Thru\", match\n",
        "        else:\n",
        "            return \"HWY Bound or Resident Entry\", match\n",
        "\n",
        "    # Rule 4: Exit\n",
        "    if ((loc == \"woodhull ave\" and direc == \"southbound\") or\n",
        "        (loc == \"lincoln ave\" and direc == \"southbound\") or\n",
        "        (loc == \"ardmer dr\" and direc == \"eastbound\") or\n",
        "        (loc == \"chereb lane\" and direc == \"eastbound\")):\n",
        "        if no_other_appearance_within(df_plate, idx, WINDOW_MIN):\n",
        "            return \"Resident Exit\", match\n",
        "\n",
        "    return \"Unclassified\", match\n",
        "\n",
        "def final_plate_classification(per_obs_classes):\n",
        "    # Priority for final roll-up\n",
        "    priority = [\"Pass Thru\", \"Resident Exit\", \"Resident Entry\", \"HWY Bound or Resident Entry\", \"Unclassified\"]\n",
        "    for label in priority:\n",
        "        if label in per_obs_classes:\n",
        "            return label\n",
        "    return \"Unclassified\"\n",
        "\n",
        "def main():\n",
        "    df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "    # Build a Timestamp from BASE_DATE + Time (e.g., \"6:00 AM\")\n",
        "    df[TIMESTAMP_COL] = pd.to_datetime(BASE_DATE + \" \" + df[TIME_COL].astype(str), errors=\"coerce\")\n",
        "\n",
        "    # Normalize for rule matching (keep originals too)\n",
        "    df[\"_loc_norm\"] = df[LOCATION_COL].map(normalize_text)\n",
        "    df[\"_dir_norm\"] = df[DIRECTION_COL].map(normalize_text)\n",
        "\n",
        "    # Use normalized fields for rules\n",
        "    df[LOCATION_COL] = df[\"_loc_norm\"]\n",
        "    df[DIRECTION_COL] = df[\"_dir_norm\"]\n",
        "\n",
        "    # Sort\n",
        "    df = df.sort_values([PLATE_COL, TIMESTAMP_COL]).reset_index(drop=True)\n",
        "\n",
        "    # Per-observation classification + match details\n",
        "    obs_cls = []\n",
        "    match_loc = []\n",
        "    match_dir = []\n",
        "    match_ts = []\n",
        "\n",
        "    for plate, plate_grp in df.groupby(PLATE_COL, sort=False):\n",
        "        df_plate = plate_grp  # already sorted slice\n",
        "        for idx in df_plate.index:\n",
        "            cls, match = classify_observation(df.loc[idx], df[df[PLATE_COL] == plate], idx)\n",
        "            obs_cls.append((idx, cls))\n",
        "            match_loc.append((idx, match[\"Match_Location\"]))\n",
        "            match_dir.append((idx, match[\"Match_Direction\"]))\n",
        "            match_ts.append((idx, match[\"Match_Timestamp\"]))\n",
        "\n",
        "    df[\"Observation_Classification\"] = pd.Series(dict(obs_cls))\n",
        "    df[\"Match_Location\"] = pd.Series(dict(match_loc))\n",
        "    df[\"Match_Direction\"] = pd.Series(dict(match_dir))\n",
        "    df[\"Match_Timestamp\"] = pd.Series(dict(match_ts))\n",
        "\n",
        "    # Plate-level final classification\n",
        "    plate_final = (\n",
        "        df.groupby(PLATE_COL)[\"Observation_Classification\"]\n",
        "          .apply(lambda s: final_plate_classification(set(s.dropna())))\n",
        "          .rename(\"Plate_Final_Classification\")\n",
        "          .reset_index()\n",
        "    )\n",
        "\n",
        "    # Merge plate final back to each row\n",
        "    df = df.merge(plate_final, on=PLATE_COL, how=\"left\")\n",
        "\n",
        "    # ---------- Output 1: full_tracking_classified.csv ----------\n",
        "    full_tracking_cols = [\n",
        "        PLATE_COL, LOCATION_COL, DIRECTION_COL, PERIOD_COL, TIME_COL, TIMESTAMP_COL,\n",
        "        \"Observation_Classification\", \"Plate_Final_Classification\",\n",
        "        \"Match_Location\", \"Match_Direction\", \"Match_Timestamp\"\n",
        "    ]\n",
        "    # Restore original-cased Location/Direction if desired\n",
        "    # (You can comment these two lines if you prefer normalized in the export)\n",
        "    if \"_loc_norm\" in df.columns and \"_dir_norm\" in df.columns:\n",
        "        df[\"Location_Original\"] = df[\"_loc_norm\"]\n",
        "        df[\"Direction_Original\"] = df[\"_dir_norm\"]\n",
        "\n",
        "    out_full = \"full_tracking_classified.csv\"\n",
        "    df[full_tracking_cols].to_csv(out_full, index=False)\n",
        "\n",
        "    # ---------- Output 2: pass_thru_summary.csv ----------\n",
        "    pass_thru = df[df[\"Observation_Classification\"] == \"Pass Thru\"].copy()\n",
        "    if not pass_thru.empty:\n",
        "        pass_thru[\"Entry_Timestamp\"] = pass_thru[TIMESTAMP_COL]\n",
        "        pass_thru[\"Exit_Timestamp\"] = pass_thru[\"Match_Timestamp\"]\n",
        "        pass_thru[\"Minutes_Between\"] = (pass_thru[\"Exit_Timestamp\"] - pass_thru[\"Entry_Timestamp\"]).dt.total_seconds() / 60.0\n",
        "        pass_thru[\"Entry_Point\"] = pass_thru[LOCATION_COL].str.title() + \" \" + pass_thru[DIRECTION_COL].str.title()\n",
        "        pass_thru[\"Exit_Point\"] = pass_thru[\"Match_Location\"].fillna(\"\").str.title() + \" \" + pass_thru[\"Match_Direction\"].fillna(\"\").str.title()\n",
        "        pass_thru[\"Path\"] = pass_thru[\"Entry_Point\"] + \" -> \" + pass_thru[\"Exit_Point\"]\n",
        "\n",
        "        pass_thru_cols = [\n",
        "            PLATE_COL, \"Entry_Timestamp\", \"Exit_Timestamp\", \"Minutes_Between\",\n",
        "            \"Entry_Point\", \"Exit_Point\", \"Path\"\n",
        "        ]\n",
        "        pass_thru = pass_thru.sort_values([PLATE_COL, \"Entry_Timestamp\"])\n",
        "        pass_thru[pass_thru_cols].to_csv(\"pass_thru_summary.csv\", index=False)\n",
        "    else:\n",
        "        # write empty schema if none\n",
        "        pd.DataFrame(columns=[\n",
        "            PLATE_COL, \"Entry_Timestamp\", \"Exit_Timestamp\", \"Minutes_Between\",\n",
        "            \"Entry_Point\", \"Exit_Point\", \"Path\"\n",
        "        ]).to_csv(\"pass_thru_summary.csv\", index=False)\n",
        "\n",
        "    # ---------- Output 3: all_movements_summary.csv ----------\n",
        "    # Aggregate by Location/Direction/Period/Time\n",
        "    grp = df.groupby([LOCATION_COL, DIRECTION_COL, PERIOD_COL, TIME_COL], dropna=False)\n",
        "    summary = grp.agg(\n",
        "        Observations=(\"Plate\", \"count\"),\n",
        "        UniquePlates=(\"Plate\", pd.Series.nunique)\n",
        "    ).reset_index()\n",
        "\n",
        "    summary = summary.sort_values([LOCATION_COL, DIRECTION_COL, PERIOD_COL, TIME_COL])\n",
        "    summary.to_csv(\"all_movements_summary.csv\", index=False)\n",
        "\n",
        "    print(f\"Saved:\\n- {out_full}\\n- pass_thru_summary.csv\\n- all_movements_summary.csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anYFlc5D3EAi",
        "outputId": "82c50eb8-f566-4a1a-e119-1ed6428e6a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved:\n",
            "- full_tracking_classified.csv\n",
            "- pass_thru_summary.csv\n",
            "- all_movements_summary.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AM/PM"
      ],
      "metadata": {
        "id": "lgjS2kTO6lmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# =========================================================\n",
        "# CONFIGURATION SECTION\n",
        "# =========================================================\n",
        "SRC = \"https://raw.githubusercontent.com/hawa1983/Traffic-Data-Bank/refs/heads/main/Port_Jefferson_LP_Count_Cleaned_no_norwood.csv\"\n",
        "\n",
        "PLATE = \"Plate\"\n",
        "LOC = \"Location\"\n",
        "PERIOD = \"Period\"     # 'AM' or 'PM'\n",
        "TIME = \"Time\"\n",
        "DIR = \"Direction\"\n",
        "\n",
        "BASE_DATE = \"2025-01-01\"\n",
        "\n",
        "FULL_OUT = \"full_tracking_classified.csv\"\n",
        "PASS_THRU_OUT = \"pass_thru_summary.csv\"\n",
        "MOVES_OUT = \"all_movements_summary.csv\"\n",
        "# =========================================================\n",
        "\n",
        "# =========================================================\n",
        "# HELPERS\n",
        "# =========================================================\n",
        "def norm(s):\n",
        "    \"\"\"Lowercase + trim, for consistent matching.\"\"\"\n",
        "    return None if pd.isna(s) else str(s).strip().lower()\n",
        "\n",
        "def to_timestamp(df):\n",
        "    \"\"\"Build datetime from a fixed date + the Time string (e.g., '6:00 AM').\"\"\"\n",
        "    return pd.to_datetime(BASE_DATE + \" \" + df[TIME].astype(str), errors=\"coerce\")\n",
        "\n",
        "def fmt_time(dt):\n",
        "    \"\"\"Pretty-print times as 'h:mm AM/PM' for Excel friendliness.\"\"\"\n",
        "    if pd.isna(dt):\n",
        "        return \"\"\n",
        "    return pd.to_datetime(dt).strftime(\"%-I:%M %p\")\n",
        "\n",
        "def find_match_within_period(df_plate, idx, target_pairs):\n",
        "    \"\"\"\n",
        "    Return the earliest FUTURE row for the same plate that:\n",
        "      - is in the SAME Period (AM/PM) as the current row, and\n",
        "      - matches ANY (location, direction) pair in target_pairs.\n",
        "    Otherwise return None.\n",
        "    \"\"\"\n",
        "    t0 = df_plate.loc[idx, \"Timestamp\"]\n",
        "    this_period = df_plate.loc[idx, PERIOD]\n",
        "\n",
        "    # Only future rows in the same AM/PM period\n",
        "    mask = (df_plate[PERIOD] == this_period) & (df_plate[\"Timestamp\"] > t0)\n",
        "    if not mask.any():\n",
        "        return None\n",
        "    future = df_plate.loc[mask]\n",
        "\n",
        "    for loc, direc in target_pairs:\n",
        "        hit = future[(future[\"loc_norm\"] == loc) & (future[\"dir_norm\"] == direc)]\n",
        "        if not hit.empty:\n",
        "            return hit.iloc[0]  # earliest such match\n",
        "    return None\n",
        "\n",
        "def any_other_location_later_in_same_period(df_plate, idx):\n",
        "    \"\"\"\n",
        "    For Rule 4: is there any FUTURE observation in the same Period at a DIFFERENT location?\n",
        "    Returns True/False.\n",
        "    \"\"\"\n",
        "    t0 = df_plate.loc[idx, \"Timestamp\"]\n",
        "    this_period = df_plate.loc[idx, PERIOD]\n",
        "    this_loc = df_plate.loc[idx, \"loc_norm\"]\n",
        "\n",
        "    mask = (df_plate[PERIOD] == this_period) & (df_plate[\"Timestamp\"] > t0)\n",
        "    if not mask.any():\n",
        "        return False\n",
        "    future_locs = df_plate.loc[mask, \"loc_norm\"]\n",
        "    return (future_locs != this_loc).any()\n",
        "\n",
        "# =========================================================\n",
        "# CLASSIFIER\n",
        "# =========================================================\n",
        "def classify_and_pair(entry_row, df_plate, idx):\n",
        "    loc = entry_row[\"loc_norm\"]\n",
        "    direc = entry_row[\"dir_norm\"]\n",
        "\n",
        "    classification = \"Unclassified\"\n",
        "    is_entry_trigger = False\n",
        "    match_row = None\n",
        "\n",
        "    # RULE 1: Entry S->N\n",
        "    if ((loc == \"woodhull ave\" and direc == \"northbound\") or\n",
        "        (loc == \"lincoln ave\" and direc == \"northbound\")):\n",
        "        is_entry_trigger = True\n",
        "        targets = [(\"ardmer dr\", \"eastbound\"), (\"chereb lane\", \"eastbound\")]\n",
        "        match_row = find_match_within_period(df_plate, idx, targets)\n",
        "        classification = \"Pass Thru\" if match_row is not None else \"No Exit\"\n",
        "\n",
        "    # RULE 2: Entry E->W\n",
        "    elif ((loc == \"ardmer dr\" and direc == \"westbound\") or\n",
        "          (loc == \"chereb lane\" and direc == \"westbound\")):\n",
        "        is_entry_trigger = True\n",
        "        targets = [(\"woodhull ave\", \"southbound\"),\n",
        "                   (\"lincoln ave\", \"southbound\"),\n",
        "                   (\"norwood ave\", \"westbound\")]\n",
        "        match_row = find_match_within_period(df_plate, idx, targets)\n",
        "        classification = \"Pass Thru\" if match_row is not None else \"No Exit\"\n",
        "\n",
        "    # RULE 3: Entry from West via Norwood EB\n",
        "    elif (loc == \"norwood ave\" and direc == \"eastbound\"):\n",
        "        is_entry_trigger = True\n",
        "        targets = [(\"ardmer dr\", \"eastbound\"), (\"chereb lane\", \"eastbound\")]\n",
        "        match_row = find_match_within_period(df_plate, idx, targets)\n",
        "        classification = \"Pass Thru\" if match_row is not None else \"HWY Bound or Resident Entry\"\n",
        "\n",
        "    # NEW RULE (COMBINED): Norwood Ave Westbound\n",
        "    # 1) If any Rule 4 exit seen later in the SAME Period → Unclassified\n",
        "    # 2) Else if any entry-trigger seen later in the SAME Period → \"Loop through <Entry Loc> <Dir>\"\n",
        "    # 3) Else → \"From Highway to Norwood Ave\"\n",
        "    elif (loc == \"norwood ave\" and direc == \"westbound\"):\n",
        "        is_entry_trigger = True\n",
        "\n",
        "        # Step 1: Rule 4 exits\n",
        "        rule4_targets = [\n",
        "            (\"woodhull ave\", \"southbound\"),\n",
        "            (\"lincoln ave\", \"southbound\"),\n",
        "            (\"ardmer dr\", \"eastbound\"),\n",
        "            (\"chereb lane\", \"eastbound\"),\n",
        "        ]\n",
        "        exit_match = find_match_within_period(df_plate, idx, rule4_targets)\n",
        "\n",
        "        if exit_match is not None:\n",
        "            classification = \"Unclassified\"\n",
        "            match_row = exit_match\n",
        "        else:\n",
        "            # Step 2: check entry triggers (Rule 1/2/3)\n",
        "            entry_targets = [\n",
        "                (\"woodhull ave\", \"northbound\"),  # Rule 1\n",
        "                (\"lincoln ave\", \"northbound\"),   # Rule 1\n",
        "                (\"ardmer dr\", \"westbound\"),      # Rule 2\n",
        "                (\"chereb lane\", \"westbound\"),    # Rule 2\n",
        "                (\"norwood ave\", \"eastbound\"),    # Rule 3\n",
        "            ]\n",
        "            entry_match = None\n",
        "            matched_pair = None\n",
        "            for pair in entry_targets:\n",
        "                m = find_match_within_period(df_plate, idx, [pair])\n",
        "                if m is not None:\n",
        "                    entry_match = m\n",
        "                    matched_pair = pair\n",
        "                    break\n",
        "\n",
        "            if entry_match is not None:\n",
        "                classification = f\"Loop through {matched_pair[0].title()} {matched_pair[1].title()}\"\n",
        "                match_row = entry_match\n",
        "            else:\n",
        "                classification = \"From Highway to Norwood Ave\"\n",
        "                match_row = None\n",
        "\n",
        "    # RULE 4: Exiting the neighborhood (period-based “no other appearance”)\n",
        "    elif ((loc == \"woodhull ave\" and direc == \"southbound\") or\n",
        "          (loc == \"lincoln ave\" and direc == \"southbound\") or\n",
        "          (loc == \"ardmer dr\" and direc == \"eastbound\") or\n",
        "          (loc == \"chereb lane\" and direc == \"eastbound\")):\n",
        "        # Resident Exit if there is NO different-location sighting later in the same AM/PM\n",
        "        if not any_other_location_later_in_same_period(df_plate, idx):\n",
        "            classification = \"Exit\"\n",
        "\n",
        "    return classification, is_entry_trigger, match_row\n",
        "\n",
        "# =========================================================\n",
        "# MAIN\n",
        "# =========================================================\n",
        "def main():\n",
        "    df = pd.read_csv(SRC)\n",
        "\n",
        "    # Keep originals for output\n",
        "    df[\"Location_orig\"] = df[LOC]\n",
        "    df[\"Direction_orig\"] = df[DIR]\n",
        "\n",
        "    # Normalize and build Timestamp\n",
        "    df[\"loc_norm\"] = df[LOC].map(norm)\n",
        "    df[\"dir_norm\"] = df[DIR].map(norm)\n",
        "    df[\"Timestamp\"] = to_timestamp(df)\n",
        "\n",
        "    # Sort by plate/time\n",
        "    df = df.sort_values([PLATE, \"Timestamp\"]).reset_index(drop=True)\n",
        "\n",
        "    # Collect outputs\n",
        "    classifications = []\n",
        "    entry_time_col, enter_col = [], []\n",
        "    exit_time_col, exit_col = [], []\n",
        "    duration_col, is_entry_trigger_col = [], []\n",
        "\n",
        "    for plate, g in df.groupby(PLATE, sort=False):\n",
        "        plate_idx = g.index\n",
        "        df_plate = df.loc[plate_idx]\n",
        "        for idx in plate_idx:\n",
        "            row = df.loc[idx]\n",
        "            cls, is_entry, match_row = classify_and_pair(row, df_plate, idx)\n",
        "            classifications.append((idx, cls))\n",
        "            is_entry_trigger_col.append((idx, is_entry))\n",
        "\n",
        "            if is_entry:\n",
        "                entry_time = row[\"Timestamp\"]\n",
        "                enter = row[\"Location_orig\"]\n",
        "                if match_row is not None:\n",
        "                    exit_time = match_row[\"Timestamp\"]\n",
        "                    exit_loc = match_row[\"Location_orig\"]\n",
        "                    mins = (exit_time - entry_time).total_seconds() / 60.0\n",
        "                else:\n",
        "                    exit_time = pd.NaT\n",
        "                    exit_loc = \"No Exit\"\n",
        "                    mins = 0\n",
        "                entry_time_col.append((idx, entry_time))\n",
        "                enter_col.append((idx, enter))\n",
        "                exit_time_col.append((idx, exit_time))\n",
        "                exit_col.append((idx, exit_loc))\n",
        "                duration_col.append((idx, mins))\n",
        "            else:\n",
        "                entry_time_col.append((idx, pd.NaT))\n",
        "                enter_col.append((idx, \"\"))\n",
        "                exit_time_col.append((idx, pd.NaT))\n",
        "                exit_col.append((idx, \"\"))\n",
        "                duration_col.append((idx, \"\"))\n",
        "\n",
        "    # Attach results\n",
        "    df[\"Classification\"] = pd.Series(dict(classifications))\n",
        "    df[\"Is_Entry_Trigger\"] = pd.Series(dict(is_entry_trigger_col))\n",
        "    df[\"Entry Time\"] = pd.Series(dict(entry_time_col)).apply(fmt_time)\n",
        "    df[\"Enter\"] = pd.Series(dict(enter_col))\n",
        "    df[\"Exit Time\"] = pd.Series(dict(exit_time_col)).apply(fmt_time)\n",
        "    df[\"Exit\"] = pd.Series(dict(exit_col))\n",
        "    df[\"Duration\"] = pd.Series(dict(duration_col))\n",
        "\n",
        "    # Restore original case\n",
        "    df[LOC] = df[\"Location_orig\"]\n",
        "    df[DIR] = df[\"Direction_orig\"]\n",
        "\n",
        "    # Save outputs\n",
        "    full_cols = [LOC, PERIOD, TIME, DIR, PLATE,\n",
        "                 \"Classification\", \"Entry Time\", \"Enter\", \"Exit Time\", \"Exit\", \"Duration\"]\n",
        "    df[full_cols].to_csv(FULL_OUT, index=False)\n",
        "\n",
        "    pt = df[(df[\"Is_Entry_Trigger\"]) & (df[\"Classification\"] == \"Pass Thru\")].copy()\n",
        "    if not pt.empty:\n",
        "        pt_out = pt[[PLATE, PERIOD, \"Entry Time\", \"Enter\", \"Exit Time\", \"Exit\", \"Duration\"]].copy()\n",
        "        pt_out[\"Duration\"] = pd.to_numeric(pt_out[\"Duration\"], errors=\"coerce\").fillna(0).round(2)\n",
        "        pt_out = pt_out.sort_values([PLATE, \"Entry Time\"])\n",
        "    else:\n",
        "        pt_out = pd.DataFrame(columns=[PLATE, PERIOD, \"Entry Time\", \"Enter\", \"Exit Time\", \"Exit\", \"Duration\"])\n",
        "    pt_out.to_csv(PASS_THRU_OUT, index=False)\n",
        "\n",
        "    moves = df[df[\"Is_Entry_Trigger\"]].copy()\n",
        "    if not moves.empty:\n",
        "        mv = (moves.groupby([PERIOD, \"Enter\", \"Exit\"], dropna=False)\n",
        "                    .size()\n",
        "                    .reset_index(name=\"Total\")\n",
        "                    .sort_values([PERIOD, \"Enter\", \"Exit\"]))\n",
        "    else:\n",
        "        mv = pd.DataFrame(columns=[PERIOD, \"Enter\", \"Exit\", \"Total\"])\n",
        "    mv.to_csv(MOVES_OUT, index=False)\n",
        "\n",
        "    print(f\"Saved:\\n- {FULL_OUT}\\n- {PASS_THRU_OUT}\\n- {MOVES_OUT}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqOl0I2B6nfS",
        "outputId": "6d9da3c1-5148-4a75-e276-7aa2d6604be9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved:\n",
            "- full_tracking_classified.csv\n",
            "- pass_thru_summary.csv\n",
            "- all_movements_summary.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chereb Eastbound Tracking"
      ],
      "metadata": {
        "id": "l-HwpbxSctsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# ========= CONFIG =========\n",
        "SRC = \"https://raw.githubusercontent.com/hawa1983/Traffic-Data-Bank/refs/heads/main/Port_Jefferson_LP_Count_Cleaned.csv\"   # change if needed\n",
        "OUT = \"CherebEB_PassThru_Tracking.csv\"                   # saves to current folder\n",
        "BASE_DATE = \"2025-01-01\"                                 # any single date ok; used to build datetimes\n",
        "# ==========================\n",
        "\n",
        "def norm(s):\n",
        "    return None if pd.isna(s) else str(s).strip().lower()\n",
        "\n",
        "def main():\n",
        "    # Load & prep\n",
        "    df = pd.read_csv(SRC)\n",
        "    # Normalize for reliable matching\n",
        "    df[\"loc_norm\"] = df[\"Location\"].map(norm)\n",
        "    df[\"dir_norm\"] = df[\"Direction\"].map(norm)\n",
        "    # Build a true timestamp (same date + provided time)\n",
        "    df[\"Timestamp\"] = pd.to_datetime(BASE_DATE + \" \" + df[\"Time\"].astype(str), errors=\"coerce\")\n",
        "    # Sort within each plate’s timeline\n",
        "    df = df.sort_values([\"Plate\", \"Timestamp\"]).reset_index(drop=True)\n",
        "\n",
        "    # Define entry conditions (ANY of these) and the target\n",
        "    entry_conditions = {\n",
        "        (\"lincoln ave\", \"northbound\"),\n",
        "        (\"woodhull ave\", \"northbound\"),\n",
        "        (\"norwood ave\", \"eastbound\"),\n",
        "    }\n",
        "    target_loc, target_dir = \"chereb lane\", \"eastbound\"\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Process per plate\n",
        "    for plate, g in df.groupby(\"Plate\", sort=False):\n",
        "        g = g.sort_values(\"Timestamp\")\n",
        "        # Iterate rows as potential entries\n",
        "        for i, entry in g.iterrows():\n",
        "            if (entry[\"loc_norm\"], entry[\"dir_norm\"]) not in entry_conditions:\n",
        "                continue\n",
        "\n",
        "            # Look for the FIRST later Chereb EB in the SAME Period (AM/PM)\n",
        "            same_period = (g[\"Period\"] == entry[\"Period\"]) & (g[\"Timestamp\"] > entry[\"Timestamp\"])\n",
        "            future = g.loc[same_period]\n",
        "\n",
        "            hit = future[(future[\"loc_norm\"] == target_loc) & (future[\"dir_norm\"] == target_dir)]\n",
        "            if hit.empty:\n",
        "                continue\n",
        "\n",
        "            exit_row = hit.iloc[0]  # earliest Chereb EB in same AM/PM\n",
        "            duration_min = (exit_row[\"Timestamp\"] - entry[\"Timestamp\"]).total_seconds() / 60.0\n",
        "\n",
        "            results.append({\n",
        "                \"Plate\": plate,\n",
        "                \"Period\": entry[\"Period\"],\n",
        "                \"Entry Time\": entry[\"Time\"],\n",
        "                \"Entry Location\": entry[\"Location\"],\n",
        "                \"Entry Direction\": entry[\"Direction\"],\n",
        "                \"Exit Time\": exit_row[\"Time\"],\n",
        "                \"Exit Location\": exit_row[\"Location\"],\n",
        "                \"Exit Direction\": exit_row[\"Direction\"],\n",
        "                \"Duration_Min\": round(duration_min, 2)\n",
        "            })\n",
        "\n",
        "    out_df = pd.DataFrame(results).sort_values([\"Period\", \"Plate\", \"Entry Time\"])\n",
        "    out_df.to_csv(OUT, index=False)\n",
        "\n",
        "    print(f\"Saved {len(out_df)} matches to: {Path(OUT).resolve()}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnTXcJBHcxJl",
        "outputId": "ad8d219a-78cb-4100-a044-db92b979bcf3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 74 matches to: /content/CherebEB_PassThru_Tracking.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ardmer Eastbound Tracking"
      ],
      "metadata": {
        "id": "2WptdMK8d4_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# ========= CONFIG =========\n",
        "SRC = \"https://raw.githubusercontent.com/hawa1983/Traffic-Data-Bank/refs/heads/main/Port_Jefferson_LP_Count_Cleaned.csv\"   # change if needed\n",
        "OUT = \"ArdmerEB_PassThru_Tracking.csv\"                   # saves to current folder\n",
        "BASE_DATE = \"2025-01-01\"                                 # any single date ok; used to build datetimes\n",
        "# ==========================\n",
        "\n",
        "def norm(s):\n",
        "    return None if pd.isna(s) else str(s).strip().lower()\n",
        "\n",
        "def main():\n",
        "    # Load & prep\n",
        "    df = pd.read_csv(SRC)\n",
        "    # Normalize for reliable matching\n",
        "    df[\"loc_norm\"] = df[\"Location\"].map(norm)\n",
        "    df[\"dir_norm\"] = df[\"Direction\"].map(norm)\n",
        "    # Build a true timestamp (same date + provided time)\n",
        "    df[\"Timestamp\"] = pd.to_datetime(BASE_DATE + \" \" + df[\"Time\"].astype(str), errors=\"coerce\")\n",
        "    # Sort within each plate’s timeline\n",
        "    df = df.sort_values([\"Plate\", \"Timestamp\"]).reset_index(drop=True)\n",
        "\n",
        "    # Define entry conditions (ANY of these) and the target\n",
        "    entry_conditions = {\n",
        "        (\"lincoln ave\", \"northbound\"),\n",
        "        (\"woodhull ave\", \"northbound\"),\n",
        "        (\"norwood ave\", \"eastbound\"),\n",
        "    }\n",
        "    target_loc, target_dir = \"ardmer dr\", \"eastbound\"\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Process per plate\n",
        "    for plate, g in df.groupby(\"Plate\", sort=False):\n",
        "        g = g.sort_values(\"Timestamp\")\n",
        "        # Iterate rows as potential entries\n",
        "        for i, entry in g.iterrows():\n",
        "            if (entry[\"loc_norm\"], entry[\"dir_norm\"]) not in entry_conditions:\n",
        "                continue\n",
        "\n",
        "            # Look for the FIRST later Ardmer EB in the SAME Period (AM/PM)\n",
        "            same_period = (g[\"Period\"] == entry[\"Period\"]) & (g[\"Timestamp\"] > entry[\"Timestamp\"])\n",
        "            future = g.loc[same_period]\n",
        "\n",
        "            hit = future[(future[\"loc_norm\"] == target_loc) & (future[\"dir_norm\"] == target_dir)]\n",
        "            if hit.empty:\n",
        "                continue\n",
        "\n",
        "            exit_row = hit.iloc[0]  # earliest Ardmer EB in same AM/PM\n",
        "            duration_min = (exit_row[\"Timestamp\"] - entry[\"Timestamp\"]).total_seconds() / 60.0\n",
        "\n",
        "            results.append({\n",
        "                \"Plate\": plate,\n",
        "                \"Period\": entry[\"Period\"],\n",
        "                \"Entry Time\": entry[\"Time\"],\n",
        "                \"Entry Location\": entry[\"Location\"],\n",
        "                \"Entry Direction\": entry[\"Direction\"],\n",
        "                \"Exit Time\": exit_row[\"Time\"],\n",
        "                \"Exit Location\": exit_row[\"Location\"],\n",
        "                \"Exit Direction\": exit_row[\"Direction\"],\n",
        "                \"Duration_Min\": round(duration_min, 2)\n",
        "            })\n",
        "\n",
        "    out_df = pd.DataFrame(results).sort_values([\"Period\", \"Plate\", \"Entry Time\"])\n",
        "    out_df.to_csv(OUT, index=False)\n",
        "\n",
        "    print(f\"Saved {len(out_df)} matches to: {Path(OUT).resolve()}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WABnCmAYd-aK",
        "outputId": "0ce60632-76a3-4e17-edec-72ae2d9f0530"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 49 matches to: /content/ArdmerEB_PassThru_Tracking.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lincoln, Woodhull, Norwood Tracking**\n",
        "\n",
        "his version tracks entries at Ardmer Dr WB or Chereb Lane WB, then keeps only those plates whose exit is Norwood Ave WB and nowhere else later in the same AM/PM period."
      ],
      "metadata": {
        "id": "jUHCzozEgMW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# ========= CONFIG =========\n",
        "SRC = \"https://raw.githubusercontent.com/hawa1983/Traffic-Data-Bank/refs/heads/main/Port_Jefferson_LP_Count_Cleaned.csv\"   # change if needed\n",
        "OUT = \"Entry_ArdmerCherebWB_To_LincolnWoodhullNorwoodWB.csv\"  # saves to current folder\n",
        "BASE_DATE = \"2025-01-01\"                                # any single date ok; used to build datetimes\n",
        "# ==========================\n",
        "\n",
        "def norm(s):\n",
        "    return None if pd.isna(s) else str(s).strip().lower()\n",
        "\n",
        "def main():\n",
        "    # Load & prep\n",
        "    df = pd.read_csv(SRC)\n",
        "    # Normalize for reliable matching\n",
        "    df[\"loc_norm\"] = df[\"Location\"].map(norm)\n",
        "    df[\"dir_norm\"] = df[\"Direction\"].map(norm)\n",
        "    # Build a true timestamp (same date + provided time)\n",
        "    df[\"Timestamp\"] = pd.to_datetime(BASE_DATE + \" \" + df[\"Time\"].astype(str), errors=\"coerce\")\n",
        "    # Sort within each plate’s timeline\n",
        "    df = df.sort_values([\"Plate\", \"Timestamp\"]).reset_index(drop=True)\n",
        "\n",
        "    # Define entry conditions (ANY of these)\n",
        "    entry_conditions = {\n",
        "        (\"ardmer dr\", \"westbound\"),\n",
        "        (\"chereb lane\", \"westbound\"),\n",
        "    }\n",
        "\n",
        "    # Define targets (ANY of these)\n",
        "    target_conditions = {\n",
        "        (\"lincoln ave\", \"southbound\"),\n",
        "        (\"woodhull ave\", \"southbound\"),\n",
        "        (\"norwood ave\", \"westbound\"),\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Process per plate\n",
        "    for plate, g in df.groupby(\"Plate\", sort=False):\n",
        "        g = g.sort_values(\"Timestamp\")\n",
        "        # Iterate rows as potential entries\n",
        "        for i, entry in g.iterrows():\n",
        "            if (entry[\"loc_norm\"], entry[\"dir_norm\"]) not in entry_conditions:\n",
        "                continue\n",
        "\n",
        "            # Look for the FIRST later target in the SAME Period (AM/PM)\n",
        "            same_period = (g[\"Period\"] == entry[\"Period\"]) & (g[\"Timestamp\"] > entry[\"Timestamp\"])\n",
        "            future = g.loc[same_period]\n",
        "\n",
        "            hit = future[future.apply(lambda r: (r[\"loc_norm\"], r[\"dir_norm\"]) in target_conditions, axis=1)]\n",
        "            if hit.empty:\n",
        "                continue\n",
        "\n",
        "            exit_row = hit.iloc[0]  # earliest match in same AM/PM\n",
        "            duration_min = (exit_row[\"Timestamp\"] - entry[\"Timestamp\"]).total_seconds() / 60.0\n",
        "\n",
        "            results.append({\n",
        "                \"Plate\": plate,\n",
        "                \"Period\": entry[\"Period\"],\n",
        "                \"Entry Time\": entry[\"Time\"],\n",
        "                \"Entry Location\": entry[\"Location\"],\n",
        "                \"Entry Direction\": entry[\"Direction\"],\n",
        "                \"Exit Time\": exit_row[\"Time\"],\n",
        "                \"Exit Location\": exit_row[\"Location\"],\n",
        "                \"Exit Direction\": exit_row[\"Direction\"],\n",
        "                \"Duration_Min\": round(duration_min, 2)\n",
        "            })\n",
        "\n",
        "    out_df = pd.DataFrame(results).sort_values([\"Period\", \"Plate\", \"Entry Time\"])\n",
        "    out_df.to_csv(OUT, index=False)\n",
        "\n",
        "    print(f\"Saved {len(out_df)} matches to: {Path(OUT).resolve()}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkYCVzIhgU3p",
        "outputId": "4ef7c357-2f50-4773-cbb2-3bd6df6780e1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 93 matches to: /content/Entry_ArdmerCherebWB_To_LincolnWoodhullNorwoodWB.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tracking at Woodlawn Ave Westbound**\n",
        "\n",
        "This keeps only entries at Norwood Ave WB where the same plate, within the same AM/PM Period, is not found anywhere at Ardmer Dr WB, Chereb Lane WB, Lincoln Ave SB, or Woodhull Ave SB."
      ],
      "metadata": {
        "id": "N7y7f7ckiSFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# ========= CONFIG =========\n",
        "SRC = \"https://raw.githubusercontent.com/hawa1983/Traffic-Data-Bank/refs/heads/main/Port_Jefferson_LP_Count_Cleaned.csv\"   # change if needed\n",
        "OUT = \"NorwoodWB_ONLY_not_ArdmerWB_CherebWB_LincolnSB_WoodhullSB.csv\"\n",
        "BASE_DATE = \"2025-01-01\"                                 # any single date ok; used to build datetimes\n",
        "# ==========================\n",
        "\n",
        "def norm(s):\n",
        "    return None if pd.isna(s) else str(s).strip().lower()\n",
        "\n",
        "def main():\n",
        "    # Load & prep\n",
        "    df = pd.read_csv(SRC)\n",
        "    df[\"loc_norm\"] = df[\"Location\"].map(norm)\n",
        "    df[\"dir_norm\"] = df[\"Direction\"].map(norm)\n",
        "    df[\"Timestamp\"] = pd.to_datetime(BASE_DATE + \" \" + df[\"Time\"].astype(str), errors=\"coerce\")\n",
        "    df = df.sort_values([\"Plate\", \"Timestamp\"]).reset_index(drop=True)\n",
        "\n",
        "    # Entry must be exactly Norwood Ave WB\n",
        "    entry_required = (\"norwood ave\", \"westbound\")\n",
        "\n",
        "    # Disallowed anywhere in SAME AM/PM Period for that plate\n",
        "    disallowed_anywhere = {\n",
        "        (\"ardmer dr\", \"westbound\"),\n",
        "        (\"chereb lane\", \"westbound\"),\n",
        "        (\"lincoln ave\", \"southbound\"),\n",
        "        (\"woodhull ave\", \"southbound\"),\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for plate, g in df.groupby(\"Plate\", sort=False):\n",
        "        g = g.sort_values(\"Timestamp\")\n",
        "\n",
        "        # iterate each Norwood WB sighting as a candidate \"entry\"\n",
        "        candidates = g[(g[\"loc_norm\"] == entry_required[0]) & (g[\"dir_norm\"] == entry_required[1])]\n",
        "        if candidates.empty:\n",
        "            continue\n",
        "\n",
        "        for _, entry in candidates.iterrows():\n",
        "            # All sightings for this plate in the same AM/PM period\n",
        "            same_period_mask = (g[\"Period\"] == entry[\"Period\"])\n",
        "            period_rows = g.loc[same_period_mask]\n",
        "\n",
        "            # Check if ANY row in that period matches the disallowed set\n",
        "            has_disallowed = period_rows.apply(\n",
        "                lambda r: (r[\"loc_norm\"], r[\"dir_norm\"]) in disallowed_anywhere, axis=1\n",
        "            ).any()\n",
        "\n",
        "            if has_disallowed:\n",
        "                continue\n",
        "\n",
        "            # Keep this Norwood WB entry\n",
        "            results.append({\n",
        "                \"Plate\": plate,\n",
        "                \"Period\": entry[\"Period\"],\n",
        "                \"Entry Time\": entry[\"Time\"],\n",
        "                \"Entry Location\": entry[\"Location\"],\n",
        "                \"Entry Direction\": entry[\"Direction\"],\n",
        "            })\n",
        "\n",
        "    out_df = pd.DataFrame(results).sort_values([\"Period\", \"Plate\", \"Entry Time\"])\n",
        "    out_df.to_csv(OUT, index=False)\n",
        "    print(f\"Saved {len(out_df)} matches to: {Path(OUT).resolve()}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oG7H3oyiaC3",
        "outputId": "7e1bdfbd-2cde-4b85-9080-091a376126b1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 577 matches to: /content/NorwoodWB_ONLY_not_ArdmerWB_CherebWB_LincolnSB_WoodhullSB.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Norwood Ave EB Trackin**\n",
        "\n",
        "This keeps only entries at Norwood Ave EB where, in the same AM/PM Period, the plate is not found at Lincoln Ave NB, Woodhull Ave NB, Chereb Lane EB, or Ardmer Dr EB:"
      ],
      "metadata": {
        "id": "ScM8kCqpjwOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# ========= CONFIG =========\n",
        "SRC = \"https://raw.githubusercontent.com/hawa1983/Traffic-Data-Bank/refs/heads/main/Port_Jefferson_LP_Count_Cleaned.csv\"   # change if needed\n",
        "OUT = \"NorwoodEB_ONLY_not_LincolnNB_WoodhullNB_CherebEB_ArdmerEB.csv\"\n",
        "BASE_DATE = \"2025-01-01\"                                 # any single date ok; used to build datetimes\n",
        "# ==========================\n",
        "\n",
        "def norm(s):\n",
        "    return None if pd.isna(s) else str(s).strip().lower()\n",
        "\n",
        "def main():\n",
        "    # Load & prep\n",
        "    df = pd.read_csv(SRC)\n",
        "    df[\"loc_norm\"] = df[\"Location\"].map(norm)\n",
        "    df[\"dir_norm\"] = df[\"Direction\"].map(norm)\n",
        "    df[\"Timestamp\"] = pd.to_datetime(BASE_DATE + \" \" + df[\"Time\"].astype(str), errors=\"coerce\")\n",
        "    df = df.sort_values([\"Plate\", \"Timestamp\"]).reset_index(drop=True)\n",
        "\n",
        "    # Entry must be exactly Norwood Ave EB\n",
        "    entry_required = (\"norwood ave\", \"eastbound\")\n",
        "\n",
        "    # Disallowed anywhere in SAME AM/PM Period for that plate\n",
        "    disallowed_anywhere = {\n",
        "        (\"lincoln ave\", \"northbound\"),\n",
        "        (\"woodhull ave\", \"northbound\"),\n",
        "        (\"chereb lane\", \"eastbound\"),\n",
        "        (\"ardmer dr\", \"eastbound\"),\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for plate, g in df.groupby(\"Plate\", sort=False):\n",
        "        g = g.sort_values(\"Timestamp\")\n",
        "\n",
        "        # All Norwood EB sightings as candidates\n",
        "        candidates = g[(g[\"loc_norm\"] == entry_required[0]) & (g[\"dir_norm\"] == entry_required[1])]\n",
        "        if candidates.empty:\n",
        "            continue\n",
        "\n",
        "        for _, entry in candidates.iterrows():\n",
        "            # Rows for this plate in the same AM/PM period\n",
        "            period_rows = g[g[\"Period\"] == entry[\"Period\"]]\n",
        "\n",
        "            # Exclude if any disallowed location/direction occurs in that period\n",
        "            has_disallowed = period_rows.apply(\n",
        "                lambda r: (r[\"loc_norm\"], r[\"dir_norm\"]) in disallowed_anywhere, axis=1\n",
        "            ).any()\n",
        "            if has_disallowed:\n",
        "                continue\n",
        "\n",
        "            # Keep this Norwood EB entry\n",
        "            results.append({\n",
        "                \"Plate\": plate,\n",
        "                \"Period\": entry[\"Period\"],\n",
        "                \"Entry Time\": entry[\"Time\"],\n",
        "                \"Entry Location\": entry[\"Location\"],\n",
        "                \"Entry Direction\": entry[\"Direction\"],\n",
        "            })\n",
        "\n",
        "    out_df = pd.DataFrame(results).sort_values([\"Period\", \"Plate\", \"Entry Time\"])\n",
        "    out_df.to_csv(OUT, index=False)\n",
        "    print(f\"Saved {len(out_df)} matches to: {Path(OUT).resolve()}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJs4_-XBkEBC",
        "outputId": "f0b35847-b1ef-47d9-bf94-5ab9811aa74a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 656 matches to: /content/NorwoodEB_ONLY_not_LincolnNB_WoodhullNB_CherebEB_ArdmerEB.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exit only**\n",
        "\n",
        "keep only plates whose entries are at one of these four targets:\n",
        "\n",
        "***Chereb Lane EB***\n",
        "\n",
        "***Ardmer Dr EB***\n",
        "\n",
        "***Woodhull Ave SB***\n",
        "\n",
        "***Lincoln Ave SB***\n",
        "\n",
        "…and ensure they are not found at any other location/direction in the same AM/PM period."
      ],
      "metadata": {
        "id": "fmR6WTNBnhpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# ========= CONFIG =========\n",
        "SRC = \"https://raw.githubusercontent.com/hawa1983/Traffic-Data-Bank/refs/heads/main/Port_Jefferson_LP_Count_Cleaned.csv\"   # change if neededOUT = \"Only_CherebEB_ArdmerEB_WoodhullSB_LincolnSB.csv\"\n",
        "OUT = \"Exit_Only.csv\"\n",
        "BASE_DATE = \"2025-01-01\"   # dummy date for timestamp building\n",
        "# ==========================\n",
        "\n",
        "def norm(s):\n",
        "    return None if pd.isna(s) else str(s).strip().lower()\n",
        "\n",
        "def main():\n",
        "    # Load & prep\n",
        "    df = pd.read_csv(SRC)\n",
        "    df[\"loc_norm\"] = df[\"Location\"].map(norm)\n",
        "    df[\"dir_norm\"] = df[\"Direction\"].map(norm)\n",
        "    df[\"Timestamp\"] = pd.to_datetime(\n",
        "        BASE_DATE + \" \" + df[\"Time\"].astype(str), errors=\"coerce\"\n",
        "    )\n",
        "    df = df.sort_values([\"Plate\", \"Timestamp\"]).reset_index(drop=True)\n",
        "\n",
        "    # Allowed entries (must be ONLY these)\n",
        "    allowed_only = {\n",
        "        (\"chereb lane\", \"eastbound\"),\n",
        "        (\"ardmer dr\", \"eastbound\"),\n",
        "        (\"woodhull ave\", \"southbound\"),\n",
        "        (\"lincoln ave\", \"southbound\"),\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for plate, g in df.groupby(\"Plate\", sort=False):\n",
        "        g = g.sort_values(\"Timestamp\")\n",
        "\n",
        "        # For each row in this plate’s timeline\n",
        "        for _, entry in g.iterrows():\n",
        "            if (entry[\"loc_norm\"], entry[\"dir_norm\"]) not in allowed_only:\n",
        "                continue\n",
        "\n",
        "            # All rows in the same AM/PM period\n",
        "            period_rows = g[g[\"Period\"] == entry[\"Period\"]]\n",
        "\n",
        "            # Check if EVERY row in that period is allowed\n",
        "            all_allowed = period_rows.apply(\n",
        "                lambda r: (r[\"loc_norm\"], r[\"dir_norm\"]) in allowed_only, axis=1\n",
        "            ).all()\n",
        "            if not all_allowed:\n",
        "                continue\n",
        "\n",
        "            # Keep this entry\n",
        "            results.append({\n",
        "                \"Plate\": plate,\n",
        "                \"Period\": entry[\"Period\"],\n",
        "                \"Entry Time\": entry[\"Time\"],\n",
        "                \"Entry Location\": entry[\"Location\"],\n",
        "                \"Entry Direction\": entry[\"Direction\"],\n",
        "            })\n",
        "\n",
        "    out_df = pd.DataFrame(results).sort_values([\"Period\", \"Plate\", \"Entry Time\"])\n",
        "    out_df.to_csv(OUT, index=False)\n",
        "    print(f\"Saved {len(out_df)} matches to: {Path(OUT).resolve()}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qM0EGic3nz3w",
        "outputId": "c802d748-b8d0-4da0-d44b-3dae8b7fb58d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 884 matches to: /content/Exit_Only.csv\n"
          ]
        }
      ]
    }
  ]
}